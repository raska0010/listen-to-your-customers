{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook we are going to use spaCy to find out what customers are complaining about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('data/biz_review_3-5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_text = reviews['text'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One focus will be on finding customer complaints about food.\n",
    "#### To do so, we will use a table with food labels and train spaCy to recognize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df = pd.read_csv('data/food_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_df[food_df['description'].str.contains('[a-zA-Z]') == True]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_labels[food_labels.str.split().apply(len) <= 2].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_labels.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = food_labels[food_labels.str.contains('.*,.*,.*', regex=True) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix: Foods are comma seperated and order is reversed: 'muffins, blueberry' become 'blueberry muffins'\n",
    "\n",
    "food_labels[food_labels.str.contains(', ') == True] = (\n",
    "    food_labels[food_labels.str.contains(', ') == True].str.split(', ', expand=True)[1] +\n",
    "    ' ' +\n",
    "    food_labels[food_labels.str.contains(', ') == True].str.split(', ', expand=True)[0]\n",
    ")\n",
    "\n",
    "food_labels[food_labels.str.contains(',') == True] = (\n",
    "    food_labels[food_labels.str.contains(',') == True].str.split(',', expand=True)[1] +\n",
    "    ' ' +\n",
    "    food_labels[food_labels.str.contains(',') == True].str.split(',', expand=True)[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If label has no plural, create singular form. If label has no singular, create plural \n",
    "\n",
    "import lemminflect\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "inflected_labels = []\n",
    "\n",
    "for label in food_labels:\n",
    "    \n",
    "    doc = nlp(label)\n",
    "\n",
    "    if len(doc) == 1:\n",
    "        if doc[0].tag_ == 'NNS':\n",
    "            inflected_labels.append(doc[0]._.inflect('NN'))\n",
    "        else:\n",
    "            inflected_labels.append(doc[0]._.inflect('NNS'))\n",
    "\n",
    "    if len(doc) == 2:\n",
    "        if doc[1].tag_ == 'NNS':\n",
    "            inflected_labels.append(doc[0].text + ' ' + doc[1]._.inflect('NN'))\n",
    "        else:\n",
    "            inflected_labels.append(doc[0].text + ' ' + doc[1]._.inflect('NNS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels_inflected = pd.Series(inflected_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels = pd.concat([food_labels, food_labels_inflected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_labels.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add food labels to entity ruler\n",
    "\n",
    "food_labels = food_labels  # Remove 'bar' from foods_labels, add 'product'\n",
    "\n",
    "patterns = []\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "ruler = nlp.add_pipe('entity_ruler', before='ner')\n",
    "\n",
    "for label in food_labels:\n",
    "    patterns.append({'label': 'FOOD', 'pattern': label})\n",
    "\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.to_disk('data/food_patterns.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now use the matcher to look for specific word patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function takes as arguments:\n",
    "# model=spaCy language model, must be stringformat\n",
    "# file=PandasSeries with strings to analyse\n",
    "# pattern=Patterns to look for\n",
    "# ruler=an entity ruler with additional entity labels, optional, must be a path in string format referring to a jsonl file\n",
    "# The name of the matcher in capital letters\n",
    "\n",
    "def match_reviews(model, file, pattern, matcher_name, ruler_path=None):\n",
    "\n",
    "   from spacy.matcher import Matcher\n",
    "    \n",
    "   nlp = spacy.load(model)\n",
    "\n",
    "   if ruler_path:\n",
    "      ruler = nlp.add_pipe(\"entity_ruler\", before='ner')\n",
    "      ruler.from_disk(ruler_path)\n",
    " \n",
    "   matcher = Matcher(nlp.vocab)\n",
    "\n",
    "   matcher.add(matcher_name, pattern, greedy='LONGEST')\n",
    "\n",
    "   matches_temp = []\n",
    "   matches = []\n",
    "\n",
    "   for text in file:\n",
    "      doc=nlp(text)\n",
    "      matches_temp = matcher(doc)\n",
    "      if matches_temp != []:\n",
    "         for match in matches_temp:\n",
    "            matches.append(doc[match[1]:match[2]].text)\n",
    "\n",
    "   return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'en_core_web_lg'\n",
    "file = reviews_text[:1000]\n",
    "pattern = [\n",
    "    [\n",
    "        {'ENT_TYPE': 'FOOD'},\n",
    "        {'LEMMA': {'IN': ['be', 'taste', 'smell']}},\n",
    "        {'DEP': 'neg', 'OP': '?'},\n",
    "        {'POS': 'ADV', 'OP': '?'},\n",
    "        {'POS': 'ADJ'}\n",
    "    ]\n",
    "]\n",
    "matcher_name = 'FOOD_MATCHER'\n",
    "ruler_path = 'data/food_patterns.jsonl'\n",
    "\n",
    "food_matches = match_reviews(model, file, pattern, matcher_name, ruler_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
